{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "110598d3-eb70-4f12-9a4b-fee4df037f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from random import randrange, uniform\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import time\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c5c558-e578-47c6-8d25-f48ab5c6c9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to compute the bearing angle from pickup point towards the destination point\n",
    "\n",
    "def get_direction(lat1, lon1, lat2, lon2):\n",
    "  lon1=lon1.to_numpy()\n",
    "  lat1=lat1.to_numpy()\n",
    "  lon2=lon2.to_numpy()\n",
    "  lat2=lat2.to_numpy()\n",
    "  diff_lon = np.deg2rad(lon2-lon1)\n",
    "  x = np.sin(diff_lon) * np.cos(lat2)\n",
    "  y = np.cos(lat1) * np.sin(lat2) - (np.sin(lat1) * np.cos(lat2) * np.cos(diff_lon))\n",
    "  initial_bearing = np.arctan2(x, y)\n",
    "\n",
    "  # Now we have the initial bearing but math.atan2 return values from -pi to + pi (in degrees)\n",
    "  direction = np.degrees (initial_bearing)\n",
    "  #if the value falls out of range, normalize it     \n",
    "  initial_bearing = np.degrees (initial_bearing)\n",
    "  direction = (initial_bearing + 360) % 360\n",
    "  return direction\n",
    "\n",
    "\n",
    "#(Source: https://www.igismap.com/haversine-formula-calculate-geographic-distance-earth/)\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "  # converting decimal degrees to radians \n",
    "\n",
    "  lon1=np.deg2rad(lon1.to_numpy())\n",
    "  lat1=np.deg2rad(lat1.to_numpy())\n",
    "  lon2=np.deg2rad(lon2.to_numpy())\n",
    "  lat2=np.deg2rad(lat2.to_numpy())\n",
    "\n",
    "  # haversine formula \n",
    "  dlon = lon2 - lon1 \n",
    "  dlat = lat2 - lat1 \n",
    "  a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "  c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    \n",
    "  r = 6372.8 # Radius of earth in kilometers. Use 3956 for miles\n",
    "  return np.around(c * r, decimals=2) \n",
    "\n",
    "\n",
    "# Load file with polygon coordinates\n",
    "def merge(list1, list2):  \n",
    "  merged_list = [(list1[i], list2[i]) for i in range(0, len(list1))] \n",
    "  return merged_list \n",
    "\n",
    "\n",
    "# Below function checks whether pick_up points are at airports\n",
    "def in_airport(x1,y1,x2,y2,airport):\n",
    "  for icoord, (x,y) in enumerate(zip([x1,x2], [y1,y2])):  \n",
    "    point = Point(float(x), float(y))  \n",
    "    found = 0 \n",
    "    polygon = Polygon(airport) \n",
    "    if polygon.contains(point) == True:\n",
    "      found = 1\n",
    "      return found\n",
    "  return found  \n",
    "\n",
    "# Below function checks whether the ride in inside manhattan\n",
    "def in_manhattan(manhattan, x, y):   \n",
    "  point = Point(float(x), float(y))  \n",
    "  found = 0\n",
    "  polygon = Polygon(manhattan) \n",
    "  if polygon.contains(point) == 1:\n",
    "    found = 1   \n",
    "    return found\n",
    "  return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "914b7c37-d7ed-4c3e-9978-2e1c349e0d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking inflation into consideration\n",
    "def inflation(infl, df1, df2):\n",
    "  inflated_fare = [0 for i in range(len(df1))]\n",
    "  inflated_fare = df2['year'].map(infl) * df1#.fare_amount \n",
    "  res = inflated_fare\n",
    "  return res\n",
    "  \n",
    "def inverse_inflation(infl, df1, df2):\n",
    "  inflated_fare = [0 for i in range(len(df1))]\n",
    "  inflated_fare = df1 / df2['year'].map(infl)\n",
    "  res = inflated_fare\n",
    "  return res\n",
    "\n",
    "#Scaling inflation to year 2009 values => till year 2015 because the data supports till year 2015\n",
    "# for years 2016 to 2021 => we estimated using the same scale\n",
    "infl = {\n",
    "    2009: 1/1.    ,\n",
    "    2010: 1/1.0164,\n",
    "    2011: 1/1.0485,\n",
    "    2012: 1/1.0702,\n",
    "    2013: 1/1.0859,\n",
    "    2014: 1/1.1035,\n",
    "    2015: 1/1.1048,\n",
    "    2016: 1/1.1103,\n",
    "    2017: 1/1.1275,\n",
    "    2018: 1/1.1418,\n",
    "    2019: 1/1.1501,\n",
    "    2020: 1/1.1583,\n",
    "    2021: 1/1.1705,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c2b658-023d-4b9c-9435-e60636dace29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data coordinates from text files for NYC airports\n",
    "JFK = open('JFK2.txt','r')\n",
    "LAGUARDIA = open('LaGuardia2.txt','r')\n",
    "NEWARK = open('Newark2.txt','r')\n",
    "airports = []\n",
    "\n",
    "jfk_coords = (40.639722, -73.778889)\n",
    "lga_coords = (40.77725, -73.872611)\n",
    "nwk_coords = (40.6925, -74.168611) \n",
    "\n",
    "for airport in [JFK, LAGUARDIA,NEWARK]:\n",
    "  for line in airport: \n",
    "    line = line.split(',')  \n",
    "    polygon_y = [ np.float64(i) for i in line[::2] ]  \n",
    "    polygon_x = [ np.float64(i) for i in line[1::2] ]   \n",
    "    airports.append(merge(polygon_x, polygon_y))  \n",
    "\n",
    "# Loading data coordinates from text file for Manhattan\n",
    "manhattan_ = open('Manhattan.txt','r')  \n",
    "for line in manhattan_:  \n",
    "  line = line.split(',')   \n",
    "  polygon_y = [ np.float64(i) for i in line[::2] ]  \n",
    "  polygon_x = [ np.float64(i) for i in line[1::2] ]   \n",
    "  manhattan = (merge(polygon_x, polygon_y))\n",
    "manhattan_.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a466a5-1aa3-41ed-ac08-f82ea7e5d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data by taking each csv file with 1M rows of 8 columns each to more than 20 columns for Neural Network\n",
    "\n",
    "for i in range(0,56):\n",
    "    file_name = \"./input_files/input\"+str(i)+\".csv\"\n",
    "    training_pd=pd.read_csv(file_name,parse_dates=['pickup_datetime'])\n",
    "    \n",
    "#     if the fare's are <0 and >30 making it an NaN so that we can replace with the mean value of the column later\n",
    "\n",
    "    training_pd.loc[training_pd['fare_amount']<0 , 'fare_amount']=np.nan\n",
    "    training_pd.loc[training_pd['fare_amount'] > 30, 'fare_amount']=np.nan\n",
    "\n",
    "    #For the case of irregular number of passenges ie., count > 8 are converted to NaN\n",
    "    training_pd.loc[training_pd['passenger_count'] > 8,'passenger_count'] = np.nan\n",
    "    df = training_pd\n",
    "\n",
    "    coutliers = [ 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
    "    for list in coutliers:\n",
    "        #Detect and replace with NA\n",
    "        #Extract quartiles\n",
    "        q75, q25 = np.percentile(df[list], [75 ,25])\n",
    "\n",
    "        #Calculate IQR\n",
    "        iqr = q75 - q25\n",
    "\n",
    "        # #Calculate inner and outer fence\n",
    "        minimum = q25 - (iqr*1.5)\n",
    "        maximum = q75 + (iqr*1.5)\n",
    "\n",
    "        # #Replace with NA\n",
    "        df.loc[df[list] < minimum,list] = np.nan\n",
    "        df.loc[df[list] > maximum,list] = np.nan\n",
    "\n",
    "        # #Calculate missing value\n",
    "        missing_val = pd.DataFrame(df.isnull().sum())\n",
    "        \n",
    "    #As it is found Mean is very close to original method we will proceed with imputation via mean\n",
    "    df.dtypes\n",
    "    \n",
    "    \n",
    "    df['year'] = df.pickup_datetime.apply(lambda t: t.year)\n",
    "    df['month'] = df.pickup_datetime.apply(lambda t: t.month)\n",
    "    df['weekday'] = df.pickup_datetime.apply(lambda t: t.weekday())\n",
    "    df['weekend'] = df['weekday'].apply(lambda t: 1 if t in [5,6] else 0)\n",
    "    df['hour'] = df.pickup_datetime.apply(lambda t: t.hour) \n",
    "    df['minute'] = df.pickup_datetime.apply(lambda t: t.minute)\n",
    "\n",
    "    df['month_sin'] = np.sin((df['month'] - 1) * (2. * np.pi / 12))\n",
    "    df['weekday_sin'] = np.sin((df['weekday'] - 1) * (2. * np.pi / 7))\n",
    "    df['hour_sin'] = np.sin((df['hour'] + df['minute'] / 60) * (2. * np.pi / 24))\n",
    "\n",
    "    # abs of delta of longitude and latitude pickup-dropoff\n",
    "    df['delta_longitude'] = abs(df.pickup_longitude - df.dropoff_longitude)\n",
    "    df['delta_latitude'] = abs(df.pickup_latitude - df.dropoff_latitude)\n",
    "    \n",
    "    # peak_hours, and inflated fare\n",
    "    df['peak_hours'] = df['hour'].apply(lambda x: 1 if x in [18,19,20] else 0)\n",
    "    df['inflated_fare'] = inflation(infl, df['fare_amount'], df) \n",
    "    \n",
    "    # Create columns 'direction', 'distance_km'\n",
    "    df['direction'] = get_direction(df['pickup_latitude'], df['pickup_longitude'], \\\n",
    "                                          df['dropoff_latitude'], df['dropoff_longitude'])\n",
    "\n",
    "    df['distance_km'] = haversine(df['pickup_latitude'], df['pickup_longitude'], \\\n",
    "                                          df['dropoff_latitude'], df['dropoff_longitude'])\n",
    "    \n",
    "        # Find how many fares begin/end at an airport\n",
    "    df['JFK']=df.apply(lambda x: in_airport(x['dropoff_latitude'], x['dropoff_longitude'], x['pickup_latitude'], x['pickup_longitude'], airports[0]),axis=1)\n",
    "    df['LGA']=df.apply(lambda x: in_airport(x['dropoff_latitude'], x['dropoff_longitude'], x['pickup_latitude'], x['pickup_longitude'], airports[1]),axis=1)\n",
    "    df['NWK']=df.apply(lambda x: in_airport(x['dropoff_latitude'], x['dropoff_longitude'], x['pickup_latitude'], x['pickup_longitude'], airports[2]),axis=1)\n",
    "\n",
    "    # Find how many fares begin/end at Manhattan\n",
    "    df['dropoff_manhattan'] = df.apply(lambda x: in_manhattan(manhattan, x['dropoff_latitude'], x['dropoff_longitude']),axis=1)\n",
    "    df['pickup_manhattan'] = df.apply(lambda x: in_manhattan(manhattan, x['pickup_latitude'], x['pickup_longitude']),axis=1)\n",
    "        \n",
    "    df['fare_amount'] = df['fare_amount'].fillna(df['fare_amount'].mean())\n",
    "    df['pickup_longitude']= df['pickup_longitude'].fillna(df['pickup_longitude'].mean())\n",
    "    df['pickup_latitude']= df['pickup_latitude'].fillna(df['pickup_latitude'].mean())\n",
    "    df['dropoff_longitude']= df['dropoff_longitude'].fillna(df['dropoff_longitude'].mean())\n",
    "    df['dropoff_latitude']= df['dropoff_latitude'].fillna(df['dropoff_latitude'].mean())\n",
    "\n",
    "    #And for category variables imputation is done with mode\n",
    "    df['passenger_count'] = df['passenger_count'].fillna(int(df['passenger_count'].mode()))\n",
    "    \n",
    "    df = df[(df['fare_amount']>0) & (df['fare_amount']<200)]\n",
    "    df = df[(df['passenger_count']>0) & (df['passenger_count']<=12)]\n",
    "    df = df[-((df['fare_amount']>70) & (df['distance_km']<5))]\n",
    "    df = df[df['distance_km']!=0]\n",
    "\n",
    "    df = df[(df['pickup_longitude']<-65) & (-85<df['pickup_longitude'])]\n",
    "    df = df[(30<df['pickup_latitude']) & (df['pickup_latitude']<55)]\n",
    "\n",
    "    df = df[(df['dropoff_longitude']<-65) & (-85<df['dropoff_longitude'])]\n",
    "    df = df[(30<df['dropoff_latitude']) & (df['dropoff_latitude']<55)]\n",
    "    \n",
    "    final_data = df.drop(columns=['key','pickup_datetime'])\n",
    "    final_data.head()\n",
    "\n",
    "    name = './preprocessed_input/file'+str(i)+'.csv'\n",
    "    final_data.to_csv(name,index=False, mode='a',)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
